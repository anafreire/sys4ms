{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def missing_data (data, percentage):\n",
    "    col_names = []\n",
    "    percentages = []\n",
    "    num_col = 0\n",
    "    for column in data:\n",
    "        zeroPercentage = sum(pd.isnull(data[column]))/len(data[column])*100\n",
    "        if zeroPercentage > 0 :\n",
    "            col_names.append(column)\n",
    "            percentages.append(zeroPercentage)\n",
    "            #print (column + \"\\t\", zeroPercentage)\n",
    "            num_col += 1\n",
    "    print(\"Missing data:\", num_col)\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.barh(col_names, percentages, alpha=0.5)\n",
    "    plt.title('Missing Data by feature (%)')\n",
    "    #plt.margins(0.2)\n",
    "    plt.xlabel('%')\n",
    "    #plt.grid() \n",
    "    plt.savefig('MissingData_Updated.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def get_columns_with_missing_data(data, percentage):\n",
    "    col_names = []\n",
    "    percentages = []\n",
    "    num_col = 0\n",
    "    for column in data:\n",
    "        zeroPercentage = sum(pd.isnull(data[column]))/len(data[column])*100\n",
    "        if zeroPercentage > 0 :\n",
    "            col_names.append(column)\n",
    "            percentages.append(zeroPercentage)\n",
    "            #print (column + \"\\t\", zeroPercentage)\n",
    "            num_col += 1\n",
    "    print(\"Missing data:\", num_col)\n",
    "    return col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_predictor_missing_data (data, n_iter, cv):\n",
    "    data_complete = data.dropna()\n",
    "    nan_columns = data.columns[data.isna().any()].tolist()\n",
    "    completed_columns = data.columns[~data.isna().any()].tolist()\n",
    "\n",
    "    X = data_complete[completed_columns]\n",
    "    y_true = data_complete[nan_columns]\n",
    "\n",
    "    CVSearch = findBestRegressorModel(X, y_true, n_iter=n_iter, cv=cv)\n",
    "    best_pred_model = CVSearch.best_estimator_\n",
    "\n",
    "    \n",
    "    return (completed_columns, nan_columns, best_pred_model, X, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting_missing_data (model, data, completed_columns, nan_columns):\n",
    "    predicted_data = pd.DataFrame(model.predict(data[completed_columns]), \n",
    "                   index=data.index,\n",
    "                   columns=nan_columns)\n",
    "    return predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_predictor_missing_data_efficient (data_complete, completed_columns, nan_column, n_iter, cv):\n",
    "    print(\"Forecasting of\", nan_column)\n",
    "\n",
    "    X = data_complete[completed_columns]\n",
    "    y_true = data_complete[nan_column]\n",
    "\n",
    "    CVSearch = findBestRegressorModel(X, y_true, n_iter=n_iter, cv=cv)\n",
    "    best_pred_model = CVSearch.best_estimator_\n",
    "\n",
    "    \n",
    "    return (best_pred_model, X, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting_missing_data_efficient (model, data, completed_columns, nan_column):\n",
    "    predicted_data = pd.DataFrame(model.predict(data[completed_columns]), \n",
    "                   index=data.index,\n",
    "                   columns=[nan_column])\n",
    "    return predicted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor (for predicting missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def findBestRegressorModel(features, target, n_iter, cv):\n",
    "    # **********Hyperparameter tuning************** \n",
    "    \n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start=int(len(features)/4), stop=int(len(features)/2), num=10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(2, 5, num = 3)]\n",
    "    #max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "  \n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    #pprint(random_grid)\n",
    "\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "\n",
    "    # First create the base model to tune\n",
    "    # rf = RandomForestClassifier(n_estimators = 50, criterion = 'entropy')\n",
    "    rf = RandomForestRegressor(n_estimators = 50, criterion = 'mse', random_state=42)\n",
    "\n",
    "\n",
    "    # Random search of parameters, using 10 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = n_iter, cv = cv, \n",
    "                                   verbose=1, random_state=42, n_jobs = -1)\n",
    "\n",
    "    # Train the model on training data\n",
    "    trained_model = rf_random.fit(features, target);\n",
    "\n",
    "    # Look at parameters used by our current forest\n",
    "    # print('Parameters found by the best estimator:\\n')\n",
    "    # pprint(rf_random.best_estimator_.get_params())\n",
    "    \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_missing_data (df, dimension, percentage):\n",
    "    \n",
    "    # Remove columns with more than X% missing data\n",
    "    for column in df:\n",
    "        nullPercentage = sum(pd.isnull(df[column]))/len(df[column])*100\n",
    "        if nullPercentage > percentage :\n",
    "            if dimension==\"columns\":\n",
    "                df = df.drop(column, axis=1)\n",
    "            else:\n",
    "                df = df.dropna(axis=0, subset=[column])\n",
    "                \n",
    "    # Predicting remaining missing data\n",
    "    completed_columns, nan_columns, best_pred_model, X, y_true = training_predictor_missing_data (df, n_iter=50, cv=10)\n",
    "    y_pred = predicting_missing_data(best_pred_model, X, completed_columns, nan_columns)\n",
    "\n",
    "\n",
    "    res = pd.DataFrame(best_pred_model.predict(df[completed_columns]), \n",
    "                   index=df.index,\n",
    "                   columns=nan_columns)\n",
    "\n",
    "    df_full = df.fillna(res)\n",
    "    return df_full\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
